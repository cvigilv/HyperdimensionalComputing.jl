var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"This page contains the complete API reference for HyperdimensionalComputing.jl.","category":"page"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"api/#Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T<:AbstractHV","page":"API","title":"Base.isapprox","text":"Base.isapprox(u::AbstractHV, v::AbstractHV, atol=length(u)/100, ptol=0.01)\n\nMeasurures when two hypervectors are similar (have more elements in common than expected by chance) using the Hamming distance. Uses a bootstrap to construct a null distribution.\n\nOne can specify either:\n\nptol=1e-10 threshold for seeing that many matches due to chance\nN_bootstap=200 number of samples for bootstrapping\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T<:Union{BinaryHV, BipolarHV}","page":"API","title":"Base.isapprox","text":"Base.isapprox(u::AbstractHV, v::AbstractHV, atol=length(u)/100, ptol=0.01)\n\nMeasurures when two hypervectors are similar (have more elements in common than expected by chance).\n\nOne can specify either:\n\natol=N/100 number of matches more than due to chance needed for being assumed similar\nptol=0.01 threshold for seeing that many matches due to chance\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.bindsequence-Tuple{AbstractVector{<:AbstractHV}}","page":"API","title":"HyperdimensionalComputing.bindsequence","text":"bindsequence(vs::AbstractVector{<:AbstractHV})\n\nBinding-based sequence. The first value is not permuted, the last value is permuted n-1 times.\n\nArguments\n\nvs::AbstractVector{<:AbstractHV}: Hypervector sequence\n\nExamples\n\njulia> vs = [BinaryHV(10) for _ in 1:10]\n10-element Vector{BinaryHV}:\n [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]\n [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n\njulia> bindsequence(vs)\n10-element BinaryHV:\n 0\n 1\n 1\n 0\n 1\n 1\n 0\n 1\n 1\n 1\n\nExtended help\n\nThis encoding is based on the following mathematical notation:\n\notimes_i=1^m Pi(V_i i-1)\n\nwhere V is the hypervector collection, m is the size of the hypervector collection, i is the position of the entry in the collection, and \\otimes and \\Pi are the binding and shift operations.\n\nReferences\n\nTorchhd documentation\n\nSee also\n\nbundlesequence: Bundle-sequence encoding, bundling-variant of this encoder\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.bipol2grad-Tuple{Real}","page":"API","title":"HyperdimensionalComputing.bipol2grad","text":"bipol2grad(x::Number)\n\nMaps a bipolar number in [-1, 1] to the [0, 1] interval.\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.bundlesequence-Tuple{AbstractVector{<:AbstractHV}}","page":"API","title":"HyperdimensionalComputing.bundlesequence","text":"bundlesequence(vs::AbstractVector{<:AbstractHV})\n\nBundling-based sequence. The first value is not permuted, the last value is permuted n-1 times.\n\nArguments\n\nvs::AbstractVector{<:AbstractHV}: Hypervector sequence\n\nExamples\n\njulia> vs = [BinaryHV(10) for _ in 1:10]\n10-element Vector{BinaryHV}:\n [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]\n [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n\njulia> bundlesequence(vs)\n10-element BinaryHV:\n 0\n 1\n 0\n 0\n 0\n 0\n 0\n 0\n 1\n 1\n\nExtended help\n\nThis encoding is based on the following mathematical notation:\n\noplus_i=1^m Pi(V_i i-1)\n\nwhere V is the hypervector collection, m is the size of the hypervector collection, i is the position of the entry in the collection, and \\oplus and \\Pi are the bundling and shift operations.\n\nReferences\n\nTorchhd documentation\n\nSee also\n\nbindsequence: Binding-sequence encoding, binding-variant of this encoder\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.crossproduct-Union{Tuple{T}, Tuple{T, T}} where T<:(AbstractVector{<:AbstractHV})","page":"API","title":"HyperdimensionalComputing.crossproduct","text":"crossproduct(U::T, V::T) where {T <: AbstractVector{<:AbstractHV}}\n\nCross product between two sets of hypervectors.\n\nArguments\n\nU::AbstractVector{<:AbstractHV}: Hypervectors\nV::AbstractVector{<:AbstractHV}: Hypervectors\n\nExamples\n\njulia> us = [BinaryHV(10) for _ in 1:5]\n5-element Vector{BinaryHV}:\n [1, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n [0, 1, 0, 0, 1, 1, 1, 0, 1, 0]\n [0, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n [0, 1, 1, 0, 1, 0, 1, 1, 1, 0]\n [1, 0, 0, 1, 0, 0, 1, 1, 1, 1]\n\njulia> vs = [BinaryHV(10) for _ in 1:5]\n5-element Vector{BinaryHV}:\n [0, 1, 1, 1, 1, 1, 0, 1, 0, 0]\n [0, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n [0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n [1, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n [1, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n\njulia> crossproduct(us, vs)\n10-element BinaryHV:\n 0\n 0\n 1\n 0\n 1\n 0\n 0\n 1\n 0\n 1\n\nExtended help\n\nThis encoding strategy first creates a multiset from both input hypervector sets, which are then bound together to generate all cross products, i.e.\n\nU₁ × V₁ + U₁ × V₂ + ... + U₁ × Vₘ + ... + Uₙ × Vₘ\n\nThis encoding is based on the following formula:\n\n(oplus_i=1^m U_i) otimes (oplus_i=1^n V_i)\n\nwhere U and V are collections of hypervectors, m and n are the sizes of the U and V collections, ì is the position in the hypervector collection, and \\oplus and \\otimes are the bundling and binding operations.\n\nReferences\n\nTorchhd documentation\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.grad2bipol-Tuple{Real}","page":"API","title":"HyperdimensionalComputing.grad2bipol","text":"grad2bipol(x::Number)\n\nMaps a graded number in [0, 1] to the [-1, 1] interval.\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.graph-Union{Tuple{T}, Tuple{T, T}} where T<:(AbstractVector{<:AbstractHV})","page":"API","title":"HyperdimensionalComputing.graph","text":"graph(source::T, target::T, directed::Bool = false)\n\nGraph for source-target pairs. Can be directed or undirected.\n\nArguments\n\nsource::T: Source node hypervectors\ntarget::T: Target node hypervectors\ndirected::Bool = false: Whether the graph is directed or not\n\nExample\n\nExtended help\n\nThis encoding is based on the following mathematical notation:\n\nUndirected graphs\n\notimes_i=1^m S_i otimes T_i\n\nDirected graphs\n\notimes_i=1^m S_i otimes Pi(T_i)\n\nwhere K and V are the key and value hypervector collections, m is the size of the hypervector collection, i is the position of the entry in the collection, and \\otimes, \\oplus and \\Pi are the binding, bundling and shift operations.\n\nSee also\n\nhashtable: Hash table encoding, underlying encoding strategy of this encoder.\n\nReferences\n\nTorchhd documentation\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.hashtable-Union{Tuple{T}, Tuple{T, T}} where T<:(AbstractVector{<:AbstractHV})","page":"API","title":"HyperdimensionalComputing.hashtable","text":"hashtable(keys::T, values::T) where {T <: AbstractVector{<:AbstractHV}}\n\nHash table from keys-values hypervector pairs. Keys and values must be the same length in order to encode as hypervector.\n\nArguments\n\nkeys::AbstractVector{<:AbstractHV}: Keys hypervectors\nvalues::AbstractVector{<:AbstractHV}: Values hypervectors\n\nExample\n\njulia> ks = [BinaryHV(10) for _ in 1:5]\n5-element Vector{BinaryHV}:\n [0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n [1, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n [0, 0, 0, 0, 1, 1, 1, 0, 1, 1]\n [1, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n [0, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n\njulia> vs = [BinaryHV(10) for _ in 1:5]\n5-element Vector{BinaryHV}:\n [0, 1, 0, 0, 1, 1, 0, 1, 0, 0]\n [1, 0, 1, 1, 1, 0, 1, 0, 0, 0]\n [0, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n [0, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n [0, 1, 1, 0, 0, 0, 1, 1, 0, 1]\n\njulia> hashtable(ks, vs)\n10-element BinaryHV:\n 0\n 0\n 0\n 1\n 1\n 0\n 1\n 0\n 1\n 1\n\nExtended help\n\nThis encoding is based on the following mathematical notation:\n\noplus_i=1^m K_i otimes V_i\n\nwhere K and V are the key and value hypervector collections, m is the size of the hypervector collection, i is the position of the entry in the collection, and \\otimes and \\oplus are the binding and bundling operations.\n\nReferences\n\nTorchhd documentation\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.level-Union{Tuple{HV}, Tuple{HV, Int64}} where HV<:AbstractHV","page":"API","title":"HyperdimensionalComputing.level","text":"level(v::HV, n::Int) where {HV <: AbstractHV}\nlevel(HV::Type{<:AbstractHV}, n::Int; dims::Int = 10_000)\n\nCreates a set of level correlated hypervectors, where the first and last hypervectors are quasi-orthogonal.\n\nArguments\n\nv::HV: Base hypervector\nn::Int: Number of levels\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.multibind-Tuple{AbstractVector{<:AbstractHV}}","page":"API","title":"HyperdimensionalComputing.multibind","text":"multibind(vs::AbstractVector{<:AbstractHV})\n\nBinding of multiple hypervectors, binds all the input hypervectors together.\n\nArguments\n\nvs::AbstractVector{<:AbstractHV}: Hypervectors\n\nExamples\n\njulia> vs = [BinaryHV(10) for _ in 1:10]\n10-element Vector{BinaryHV}:\n [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]\n [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n\njulia> multibind(vs)\n10-element BinaryHV:\n 1\n 1\n 1\n 0\n 1\n 1\n 1\n 0\n 1\n 0\n\nExtended help\n\nThis encoding is based on the following mathematical notation:\n\notimes_i=1^m V_i\n\nwhere V is the hypervector collection, m is the size of the hypervector collection, i is the position of the entry in the collection, and \\otimes is the binding operation.\n\nReferences\n\nTorchhd documentation\n\nSee also\n\nmultiset: Multiset encoding, bundling-variant of this encoder\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.multiset-Union{Tuple{AbstractVector{<:T}}, Tuple{T}} where T<:AbstractHV","page":"API","title":"HyperdimensionalComputing.multiset","text":"multiset(vs::AbstractVector{<:T})::T where {T <: AbstractHV}\n\nMultiset of input hypervectors, bundles all the input hypervectors together.\n\nArguments\n\nvs::AbstractVector{<:AbstractHV}: Hypervectors\n\nExample\n\njulia> vs = [BinaryHV(10) for _ in 1:10]\n10-element Vector{BinaryHV}:\n [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]\n [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n\njulia> multiset(vs)\n10-element BinaryHV:\n 0\n 1\n 0\n 0\n 1\n 0\n 0\n 0\n 1\n 0\n\nExtended help\n\nThis encoding is based on the following mathematical notation:\n\noplus_i=1^m V_i\n\nwhere V is the hypervector collection, m is the size of the hypervector collection, i is the position of the entry in the collection, and \\oplus is the bundling operation.\n\nReferences\n\nTorchhd documentation\n\nSee also\n\nmultibind: Multibind encoding, binding-variant of this encoder\n\n\n\n\n\n","category":"method"},{"location":"api/#HyperdimensionalComputing.ngrams","page":"API","title":"HyperdimensionalComputing.ngrams","text":"ngrams(vs::AbstractVector{<:AbstractHV}, n::Int = 3)\n\nCreates a hypervector with the n-gram statistics of the input.\n\nArguments\n\nvs::AbstractVector{<:AbstractHV}: Hypervector collection\nn::Int = 3: n-gram size\n\nExamples\n\njulia> vs = [BinaryHV(10) for _ in 1:10]\n10-element Vector{BinaryHV}:\n [0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n [0, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n [0, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n [1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n [0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n [1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n [0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n [0, 0, 0, 1, 1, 1, 1, 0, 0, 1]\n [1, 1, 0, 0, 0, 1, 1, 1, 0, 1]\n\njulia> ngrams(vs)\n10-element BinaryHV:\n 1\n 1\n 1\n 1\n 1\n 1\n 0\n 1\n 0\n 1\n\nExtended help\n\nThis encoding is defined by the following mathematical notation:\n\noplus_i=1^m-notimes_j=1^n-1Pi^n-j-1(V_i+j)\n\nwhere V is the collection of hypervectors, m is the number of hypervectors in the collection V, n is the window size, i is the position in the sequence, j is the position in the n-gram, and \\oplus, \\otimes and \\Pi are the bundling, binding and shift operations.\n\nnote: Note\nFor n = 1 use multiset() instead\nFor n = m use bindsequence() instead\n\nSee also\n\nmultiset: Multiset encoding, equivalent to ngram(vs, 1)\nbindsequence: Bind-sequence encoding, equivalent to ngram(vs, length(vs))\n\nReferences\n\nTorchhd documentation\n\n\n\n\n\n","category":"function"},{"location":"api/#Types","page":"API","title":"Types","text":"","category":"section"},{"location":"api/#Constants","page":"API","title":"Constants","text":"","category":"section"},{"location":"api/#Macros","page":"API","title":"Macros","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"using Handcalcs #hide","category":"page"},{"location":"examples/introduction-to-hdc/#Introduction","page":"Introduction to HDC","title":"Introduction","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Hyperdimensional Computing (HDC) is a brain-inspired computational paradigm that represents and manipulates information using high-dimensional vectors called hypervectors. These vectors typically have thousands of dimensions (often 1,000-10,000), making them \"hyperdimensional.\"","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"The key insight is that high-dimensional spaces have unique mathematical properties that allow for robust, fault-tolerant computation.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Let's start by loading the package in question, as follows:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"using HyperdimensionalComputing","category":"page"},{"location":"examples/introduction-to-hdc/#Creating-hypervectors","page":"Introduction to HDC","title":"Creating hypervectors","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"First, we will create a random bipolar hypervector. This is done as follows:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"BipolarHV()","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"As you may see, by default the hypervector created has 10.000 dimensions. This is the default value in HyperdimensionalComputing.jl, but one can can create a hypervector of any given dimensionality by providing the size of this as an argument:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"BipolarHV(8)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Alternatively, one can create a hypervector directly from a AbstractVector:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"BipolarHV(rand([-1, 1], 8))","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Let's create 3 bipolar hypervector to use for the tutorial:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ = BipolarHV(8)\nh₂ = BipolarHV(8)\nh₃ = BipolarHV(8);\nnothing #hide","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"The package has different hypervector types, such as BipolarHV, TernaryHV, RealHV, GradedBipolarHV, and GradedHV. All of this hypervectors have a common abstract type AbstractHV which can be used to build additional functions or encoding strategies (more on both later).","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"info: On (abstract) types\nAll hypervectors implemented on HyperdimensionalComputing.jl can be found by checking the docstrings for the AbstractHV (by typing ?AbstractHV on the Julia REPL).For more information on a specific hypervector type, the docstrings contain information on the implementation, operations, similarity measurement and other technical characteristics.","category":"page"},{"location":"examples/introduction-to-hdc/#Fundamental-operations-with-hypervectors","page":"Introduction to HDC","title":"Fundamental operations with hypervectors","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"HDC uses three primary operations that preserve the hyperdimensional properties and allow for the representation more complex structures:","category":"page"},{"location":"examples/introduction-to-hdc/#Bundling","page":"Introduction to HDC","title":"Bundling","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Bundling (also known as superposition) combines multiple hypervectors to create a new hypervector that is similar to it's constituyents.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"u = h_1 + h_2 + h_3","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"where  denotes a potential normalization operations. In the case of bipolar hypervectors, this normalization operation is the sign function, which is defined as follows:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"textsign(i) = begincases\n  +1  textif  i  0 \n  -1  textif  i  0 \n   0  textotherwise \nendcases","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"In HyperdimensionalComputing.jl, you can bundle hypervectors as follows:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"bundle([h₁, h₂, h₃])","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"alternatively, you can use the + operator (which if overloaded for all AbstractHV):","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ + h₂ + h₃","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"This operation generates a hypervector that is similar to all it's contituyent hypervectors, such that","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ sim u h₂ sim u h₃ sim u","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"where sim means that the hypervectors are similar, i.e. they share more components than expected by chance.","category":"page"},{"location":"examples/introduction-to-hdc/#Binding","page":"Introduction to HDC","title":"Binding","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Binding combines multiple hypervectors to create a new hypervector that is dissimilar to it's constituyents, such that:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"v = h₁ times h₂ times h₃","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"where  represents a normalization procedure.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"In HyperdimensionalComputing.jl, you can bind hypervectors as follows:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"bind([h₁, h₂, h₃])","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"alternatively, you can use the * operator (which if overloaded for all AbstractHV):","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ * h₂ * h₃","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"This operation generates a hypervector that is similar to all it's contituyent hypervectors, such that","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ nsim v h₂ nsim v h₃ nsim v","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"where nsim means that the hypervectors are dissimilar, i.e. they are quasi-orthogonal.","category":"page"},{"location":"examples/introduction-to-hdc/#Permutation","page":"Introduction to HDC","title":"Permutation","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Permutation (also known as shifting) is a special case of binding that creates a variant of a single hypervector via, generally speaking, a circular vector shifting with one or more positions.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"m = rho(h₁)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"@handcalcs h₁ # hide","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"@handcalcs ρ(h₁) # hide","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"@handcalcs h₁ != ρ(h₁) # hide","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"The new hypervector will be, in principle, dissimilar to it's original version, such that:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h_1 nsim rho(h_1) nsim rhorho(h_1) nsim rhorho(h_1) ","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"where nsim means that the hypervectors are dissimilar, i.e. they are quasi-orthogonal.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"In HyperdimensionalComputing.jl, one can shift hypervector as follows:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"ρ(h₁, 1)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ != ρ(h₁, 1) != ρ(h₁, 2) != ρ(h₁, 3)","category":"page"},{"location":"examples/introduction-to-hdc/#Similarity","page":"Introduction to HDC","title":"Similarity","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Althought technically not an operation, in order to retrieve information from hypervectors, we need to compare them using similarity/distance functions. HyperdimensionalComputing.jl provides a handy similarity function that accepts:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"2 hypervectors:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"similarity(h₁, h₂)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"A vector of hypervectors:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"similarity(h₁, h₁)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"or a hypervector and a vector of hypervectors:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"similarity.(Ref(h₁), [h₁, h₂, h₃])","category":"page"},{"location":"examples/introduction-to-hdc/#Encoding-things-as-hypervectors","page":"Introduction to HDC","title":"Encoding things as hypervectors","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"The true power of HDC emerges when we combine the fundamental operations to encode complex data structures as hypervectors. By creatively applying bundling, binding, and shifting, we can represent virtually any type of information - from sequences and hierarchies to graphs and associative memories. The operations act as building blocks that can be composed in countless ways, limited only by our imagination and the specific requirements of our application. Let's explore some fundamental encoding strategies that demonstrate this flexibility.","category":"page"},{"location":"examples/introduction-to-hdc/#Key-value-pairs","page":"Introduction to HDC","title":"Key-value pairs","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Animal hypervectors:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"dog_hv = BipolarHV()\ncat_hv = BipolarHV()\ncow_hv = BipolarHV()\nanimals = [dog_hv, cat_hv, cow_hv]","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Sound hypervectors:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"bark_hv = BipolarHV()\nmeow_hv = BipolarHV()\nmoo_hv = BipolarHV()\nsounds = [bark_hv, meow_hv, moo_hv]","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Associative memory:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"memory = (dog_hv * bark_hv) + (cat_hv * meow_hv) + (cow_hv * moo_hv);\nnothing #hide","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Querying memory to search for dog's sound:","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"findmax(hv -> similarity(memory * dog_hv, hv), sounds)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Querying memory to search which animals goes \"moo\":","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"findmax(hv -> similarity(memory * moo_hv, hv), animals)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"This is a very simple example, but you could think of having a more complex thing going on or having more animal that, for example, share sounds.","category":"page"},{"location":"examples/introduction-to-hdc/#Sequences","page":"Introduction to HDC","title":"Sequences","text":"","category":"section"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"N-grams represent sequences by encoding the order of elements. This is particularly useful for text processing where word order matters.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Generate hypervectors for all characters in the alphabet","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"char2hv = Dict(c => BipolarHV() for c in 'a':'z')\nchar2hv[' '] = BipolarHV()","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Encode the phrases using 3-grams","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"phrases = [\n    \"the quick brown fox jumps over the lazy dog\",\n    \"the slick grown box bumps under the hazy fog\",\n    \"the thick known cox dumps inter the crazy cog\",\n    \"the brick shown pox lumps enter the glazy jog\",\n    \"the stick blown sox pumps winter the blazy log\",\n]\n\nngrams(p, d) = bundle([d[p[i]] + shift(d[p[i + 1]], 1) + shift(d[p[i + 2]], 2) for i in 1:(length(p) - 2)])\n\nphrases_hvs = [ngrams(p, char2hv) for p in phrases]","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Search for \"crazy\" in phrases","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"query = ngrams(\"crazy\", char2hv)\nfindmax(h -> similarity(query, h), phrases_hvs)","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"Great! We correctly found that \"crazy\" is in phrase 3.","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"","category":"page"},{"location":"examples/introduction-to-hdc/","page":"Introduction to HDC","title":"Introduction to HDC","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/#Replicating-\"What’s-the-Dollar-of-Mexico?\"-in-HyperdimensionalComputing.jl","page":"What's the Dollar of Mexico?","title":"Replicating \"What’s the Dollar of Mexico?\" in HyperdimensionalComputing.jl","text":"","category":"section"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"using HyperdimensionalComputing\nusing LinearAlgebra #hide","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"Concept hypervectors","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"COUNTRY = BipolarHV()\nCAPITAL = BipolarHV()\nMONEY = BipolarHV()","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"Holistic representation of countries","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"USA = BipolarHV()\nMEX = BipolarHV()\n\nWDC = BipolarHV()\nMXC = BipolarHV()\n\nDOL = BipolarHV()\nPES = BipolarHV()\n\nUSTATES = (COUNTRY * USA) + (CAPITAL * WDC) + (MONEY * DOL)\nMEXICO = (COUNTRY * MEX) + (CAPITAL * MXC) + (MONEY * PES)","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"USTATES ≈ MEXICO","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"If we now pair USTATES with MEXICO, we get a bundle that pairs USA with Mexico, Washington DC with Mexico City, and dollar with peso, plus noise:","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"F_UM = USTATES * MEXICO","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"What in Mexico corresponds to United States' dollar:","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"DOL * F_UM ≈ PES","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"SWE = BipolarHV()\nSTO = BipolarHV()\nKRO = BipolarHV()\n\nSWEDEN = (COUNTRY * SWE) + (CAPITAL * STO) + (MONEY * KRO)","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"F_UM = USTATES * MEXICO\nF_SU = SWEDEN * USTATES\nF_SM = SWEDEN * MEXICO\n\nF_SU * F_UM ≈ F_SM","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"USTATES * DOL ≈ MEXICO * PES","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"USTATES * DOL * MEXICO ≈ PES","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"USTATES * DOL * MEXICO ≈ KRO","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"USTATES * DOL * MEXICO ≈ DOL","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"","category":"page"},{"location":"examples/whats-the-dollar-of-mexico/","page":"What's the Dollar of Mexico?","title":"What's the Dollar of Mexico?","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#HyperdimensionalComputing.jl","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"","category":"section"},{"location":"","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"Documentation for HyperdimensionalComputing.","category":"page"},{"location":"#Overview","page":"HyperdimensionalComputing.jl","title":"Overview","text":"","category":"section"},{"location":"","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"HyperdimensionalComputing.jl provides...","category":"page"},{"location":"#Manual","page":"HyperdimensionalComputing.jl","title":"Manual","text":"","category":"section"},{"location":"","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"Pages = [\n    \"api.md\",\n    \"examples.md\"\n]\nDepth = 2","category":"page"},{"location":"#Index","page":"HyperdimensionalComputing.jl","title":"Index","text":"","category":"section"},{"location":"","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"Pages = [\"index.md\"]","category":"page"},{"location":"developers/#Developer-guide","page":"Developer guide","title":"Developer guide","text":"","category":"section"},{"location":"developers/#Formatting","page":"Developer guide","title":"Formatting","text":"","category":"section"},{"location":"developers/","page":"Developer guide","title":"Developer guide","text":"We use Runic.jl to format the HyperdimensionalComputing.jl codebase. We recommend installing pre-commit to automatically set up pre-commit hooks that check code formatting. To install the pre-commit hooks, run pre-commit install in the root directory. After installation, the hooks will run automatically on each commit.","category":"page"},{"location":"developers/","page":"Developer guide","title":"Developer guide","text":"Since implementing comprehensive development tooling can be challenging, pull requests that don't follow Runic.jl formatting will be automatically revised with review comments indicating the required changes. We strongly encourage contributors to format their code before submitting pull requests, as large unformatted PRs can be difficult to review and may cause significant delays in the review process.","category":"page"}]
}
