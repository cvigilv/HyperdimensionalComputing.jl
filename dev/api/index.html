<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · HyperdimensionalComputing.jl</title><meta name="title" content="API · HyperdimensionalComputing.jl"/><meta property="og:title" content="API · HyperdimensionalComputing.jl"/><meta property="twitter:title" content="API · HyperdimensionalComputing.jl"/><meta name="description" content="Documentation for HyperdimensionalComputing.jl."/><meta property="og:description" content="Documentation for HyperdimensionalComputing.jl."/><meta property="twitter:description" content="Documentation for HyperdimensionalComputing.jl."/><meta property="og:url" content="https://cvigilv.github.io/HyperdimensionalComputing.jl/api/"/><meta property="twitter:url" content="https://cvigilv.github.io/HyperdimensionalComputing.jl/api/"/><link rel="canonical" href="https://cvigilv.github.io/HyperdimensionalComputing.jl/api/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">HyperdimensionalComputing.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">HyperdimensionalComputing.jl</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/introduction-to-hdc/">Introduction to HDC</a></li><li><a class="tocitem" href="../examples/whats-the-dollar-of-mexico/">What&#39;s the Dollar of Mexico?</a></li></ul></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li><li><a class="tocitem" href="#Types"><span>Types</span></a></li><li><a class="tocitem" href="#Constants"><span>Constants</span></a></li><li><a class="tocitem" href="#Macros"><span>Macros</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/main/docs/src/api.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><p>This page contains the complete API reference for HyperdimensionalComputing.jl.</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#HyperdimensionalComputing.BinaryHV"><code>HyperdimensionalComputing.BinaryHV</code></a></li><li><a href="#HyperdimensionalComputing.TernaryHV"><code>HyperdimensionalComputing.TernaryHV</code></a></li><li><a href="#Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Union{BinaryHV, BipolarHV}"><code>Base.isapprox</code></a></li><li><a href="#Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T&lt;:AbstractHV"><code>Base.isapprox</code></a></li><li><a href="#HyperdimensionalComputing.bindsequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.bindsequence</code></a></li><li><a href="#HyperdimensionalComputing.bipol2grad-Tuple{Real}"><code>HyperdimensionalComputing.bipol2grad</code></a></li><li><a href="#HyperdimensionalComputing.bundlesequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.bundlesequence</code></a></li><li><a href="#HyperdimensionalComputing.convertlevel-Tuple{Any, Vararg{Any}}"><code>HyperdimensionalComputing.convertlevel</code></a></li><li><a href="#HyperdimensionalComputing.crossproduct-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>HyperdimensionalComputing.crossproduct</code></a></li><li><a href="#HyperdimensionalComputing.decodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Any}"><code>HyperdimensionalComputing.decodelevel</code></a></li><li><a href="#HyperdimensionalComputing.encodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Any}"><code>HyperdimensionalComputing.encodelevel</code></a></li><li><a href="#HyperdimensionalComputing.encodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Number, Number}"><code>HyperdimensionalComputing.encodelevel</code></a></li><li><a href="#HyperdimensionalComputing.grad2bipol-Tuple{Real}"><code>HyperdimensionalComputing.grad2bipol</code></a></li><li><a href="#HyperdimensionalComputing.graph-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>HyperdimensionalComputing.graph</code></a></li><li><a href="#HyperdimensionalComputing.hashtable-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>HyperdimensionalComputing.hashtable</code></a></li><li><a href="#HyperdimensionalComputing.level-Union{Tuple{HV}, Tuple{HV, Int64}} where HV&lt;:AbstractHV"><code>HyperdimensionalComputing.level</code></a></li><li><a href="#HyperdimensionalComputing.multibind-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.multibind</code></a></li><li><a href="#HyperdimensionalComputing.multiset-Union{Tuple{AbstractVector{&lt;:T}}, Tuple{T}} where T&lt;:AbstractHV"><code>HyperdimensionalComputing.multiset</code></a></li><li><a href="#HyperdimensionalComputing.nearest_neighbor-Tuple{AbstractHV, Any, Int64}"><code>HyperdimensionalComputing.nearest_neighbor</code></a></li><li><a href="#HyperdimensionalComputing.ngrams"><code>HyperdimensionalComputing.ngrams</code></a></li><li><a href="#HyperdimensionalComputing.similarity-Tuple{AbstractHV}"><code>HyperdimensionalComputing.similarity</code></a></li><li><a href="#HyperdimensionalComputing.similarity-Tuple{AbstractVector, AbstractVector}"><code>HyperdimensionalComputing.similarity</code></a></li><li><a href="#HyperdimensionalComputing.similarity-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.similarity</code></a></li><li><a href="#HyperdimensionalComputing.δ"><code>HyperdimensionalComputing.δ</code></a></li></ul><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T&lt;:AbstractHV"><a class="docstring-binding" href="#Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T&lt;:AbstractHV"><code>Base.isapprox</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">Base.isapprox(u::AbstractHV, v::AbstractHV, atol=length(u)/100, ptol=0.01)</code></pre><p>Measurures when two hypervectors are similar (have more elements in common than expected by chance) using the Hamming distance. Uses a bootstrap to construct a null distribution.</p><p>One can specify either:</p><ul><li><code>ptol=1e-10</code> threshold for seeing that many matches due to chance</li><li><code>N_bootstap=200</code> number of samples for bootstrapping</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/operations.jl#L214-L223">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Union{BinaryHV, BipolarHV}"><a class="docstring-binding" href="#Base.isapprox-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Union{BinaryHV, BipolarHV}"><code>Base.isapprox</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">Base.isapprox(u::AbstractHV, v::AbstractHV, atol=length(u)/100, ptol=0.01)</code></pre><p>Measurures when two hypervectors are similar (have more elements in common than expected by chance).</p><p>One can specify either:</p><ul><li><code>atol=N/100</code> number of matches more than due to chance needed for being assumed similar</li><li><code>ptol=0.01</code> threshold for seeing that many matches due to chance</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/operations.jl#L194-L203">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.bindsequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><a class="docstring-binding" href="#HyperdimensionalComputing.bindsequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.bindsequence</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">bindsequence(vs::AbstractVector{&lt;:AbstractHV})</code></pre><p>Binding-based sequence. The first value is not permuted, the last value is permuted n-1 times.</p><p><strong>Arguments</strong></p><ul><li><code>vs::AbstractVector{&lt;:AbstractHV}</code>: Hypervector sequence</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; vs = [BinaryHV(10) for _ in 1:10]
10-element Vector{BinaryHV}:
 [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]
 [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]
 [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]
 [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]
 [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]
 [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]
 [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]
 [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]
 [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]
 [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]

julia&gt; bindsequence(vs)
10-element BinaryHV:
 0
 1
 1
 0
 1
 1
 0
 1
 1
 1</code></pre><p><strong>Extended help</strong></p><p>This encoding is based on the following mathematical notation:</p><p class="math-container">\[\otimes_{i=1}^{m} \Pi(V_i, i-1)\]</p><p>where <code>V</code> is the hypervector collection, <code>m</code> is the size of the hypervector collection, <code>i</code> is the position of the entry in the collection, and <code>\otimes</code> and <code>\Pi</code> are the binding and shift operations.</p><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.bind_sequence.html">Torchhd documentation</a></li></ul><p><strong>See also</strong></p><ul><li><a href="#HyperdimensionalComputing.bundlesequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>bundlesequence</code></a>: Bundle-sequence encoding, bundling-variant of this encoder</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L184-L240">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.bipol2grad-Tuple{Real}"><a class="docstring-binding" href="#HyperdimensionalComputing.bipol2grad-Tuple{Real}"><code>HyperdimensionalComputing.bipol2grad</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>bipol2grad(x::Number)</p><p>Maps a bipolar number in [-1, 1] to the [0, 1] interval.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/operations.jl#L24-L28">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.bundlesequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><a class="docstring-binding" href="#HyperdimensionalComputing.bundlesequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.bundlesequence</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">bundlesequence(vs::AbstractVector{&lt;:AbstractHV})</code></pre><p>Bundling-based sequence. The first value is not permuted, the last value is permuted n-1 times.</p><p><strong>Arguments</strong></p><ul><li><code>vs::AbstractVector{&lt;:AbstractHV}</code>: Hypervector sequence</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; vs = [BinaryHV(10) for _ in 1:10]
10-element Vector{BinaryHV}:
 [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]
 [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]
 [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]
 [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]
 [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]
 [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]
 [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]
 [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]
 [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]
 [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]

julia&gt; bundlesequence(vs)
10-element BinaryHV:
 0
 1
 0
 0
 0
 0
 0
 0
 1
 1</code></pre><p><strong>Extended help</strong></p><p>This encoding is based on the following mathematical notation:</p><p class="math-container">\[\oplus_{i=1}^{m} \Pi(V_i, i-1)\]</p><p>where <code>V</code> is the hypervector collection, <code>m</code> is the size of the hypervector collection, <code>i</code> is the position of the entry in the collection, and <code>\oplus</code> and <code>\Pi</code> are the bundling and shift operations.</p><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.bundle_sequence.html">Torchhd documentation</a></li></ul><p><strong>See also</strong></p><ul><li><a href="#HyperdimensionalComputing.bindsequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>bindsequence</code></a>: Binding-sequence encoding, binding-variant of this encoder</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L122-L178">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.convertlevel-Tuple{Any, Vararg{Any}}"><a class="docstring-binding" href="#HyperdimensionalComputing.convertlevel-Tuple{Any, Vararg{Any}}"><code>HyperdimensionalComputing.convertlevel</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">convertlevel(hvlevels, numvals..., kwargs...)</code></pre><p>Creates the <code>encoder</code> and <code>decoder</code> for a level incoding in one step. See <code>encodelevel</code> and <code>decodelevel</code> for their respective documentations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L596-L601">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.crossproduct-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><a class="docstring-binding" href="#HyperdimensionalComputing.crossproduct-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>HyperdimensionalComputing.crossproduct</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">crossproduct(U::T, V::T) where {T &lt;: AbstractVector{&lt;:AbstractHV}}</code></pre><p>Cross product between two sets of hypervectors.</p><p><strong>Arguments</strong></p><ul><li><code>U::AbstractVector{&lt;:AbstractHV}</code>: Hypervectors</li><li><code>V::AbstractVector{&lt;:AbstractHV}</code>: Hypervectors</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; us = [BinaryHV(10) for _ in 1:5]
5-element Vector{BinaryHV}:
 [1, 1, 1, 1, 1, 0, 0, 1, 0, 0]
 [0, 1, 0, 0, 1, 1, 1, 0, 1, 0]
 [0, 1, 1, 1, 1, 0, 0, 1, 1, 1]
 [0, 1, 1, 0, 1, 0, 1, 1, 1, 0]
 [1, 0, 0, 1, 0, 0, 1, 1, 1, 1]

julia&gt; vs = [BinaryHV(10) for _ in 1:5]
5-element Vector{BinaryHV}:
 [0, 1, 1, 1, 1, 1, 0, 1, 0, 0]
 [0, 0, 1, 0, 0, 1, 1, 0, 0, 1]
 [0, 0, 0, 0, 1, 0, 0, 1, 0, 1]
 [1, 0, 1, 1, 0, 1, 1, 1, 1, 1]
 [1, 0, 1, 0, 0, 1, 0, 1, 0, 1]

julia&gt; crossproduct(us, vs)
10-element BinaryHV:
 0
 0
 1
 0
 1
 0
 0
 1
 0
 1</code></pre><p><strong>Extended help</strong></p><p>This encoding strategy first creates a multiset from both input hypervector sets, which are then bound together to generate all cross products, i.e.</p><p>U₁ × V₁ + U₁ × V₂ + ... + U₁ × Vₘ + ... + Uₙ × Vₘ</p><p>This encoding is based on the following formula:</p><p class="math-container">\[(\oplus_{i=1}^{m} U_i) \otimes (\oplus_{i=1}^{n} V_i)\]</p><p>where U and V are collections of hypervectors, <code>m</code> and <code>n</code> are the sizes of the U and V collections, <code>ì</code> is the position in the hypervector collection, and <code>\oplus</code> and <code>\otimes</code> are the bundling and binding operations.</p><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.cross_product.html">Torchhd documentation</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L309-L371">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.decodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Any}"><a class="docstring-binding" href="#HyperdimensionalComputing.decodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Any}"><code>HyperdimensionalComputing.decodelevel</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">decodelevel(hvlevels::AbstractVector{&lt;:AbstractHV}, numvalues)</code></pre><p>Generate a decoding function based on <code>level</code>, for decoding numerical values. It returns a function that gives the numerical value for a given hypervector, based on similarity matching.</p><p><strong>Arguments</strong></p><ul><li>hvlevels::AbstractVector{&lt;:AbstractHV}: vector of hypervectors representing the level encoding</li><li>numvalues: the range or vector with the corresponding numerical values</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">numvalues = range(0, 2pi, 100)
hvlevels = level(BipolarHV(), 100)

decoder = decodelevel(hvlevels, numvalues)

decoder(hvlevels[17])  # value that closely matches the corresponding HV</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L562-L581">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.encodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Any}"><a class="docstring-binding" href="#HyperdimensionalComputing.encodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Any}"><code>HyperdimensionalComputing.encodelevel</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">encodelevel(hvlevels::AbstractVector{&lt;:AbstractHV}, numvalues; testbound=false)</code></pre><p>Generate an encoding function based on <code>level</code>, for encoding numerical values. It returns a function that gives the corresponding hypervector for a given numerical input.</p><p><strong>Arguments</strong></p><ul><li>hvlevels::AbstractVector{&lt;:AbstractHV}: vector of hypervectors representing the level encoding</li><li>numvalues: the range or vector with the corresponding numerical values</li><li>[testbound=false]: optional keyword argument to check whether the provided value is in bounds</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">numvalues = range(0, 2pi, 100)
hvlevels = level(BipolarHV(), 100)

encoder = encodelevel(hvlevels, numvalues)

encoder(pi/3)  # hypervector that best represents this numerical value</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L520-L540">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.encodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Number, Number}"><a class="docstring-binding" href="#HyperdimensionalComputing.encodelevel-Tuple{AbstractVector{&lt;:AbstractHV}, Number, Number}"><code>HyperdimensionalComputing.encodelevel</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">encodelevel(hvlevels::AbstractVector{&lt;:AbstractHV}, a::Number, b::Number; testbound=false)</code></pre><p>See <code>encodelevel</code>, same but provide lower (<code>a</code>) and upper (<code>b</code>) limit of the interval to be encoded.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L552-L556">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.grad2bipol-Tuple{Real}"><a class="docstring-binding" href="#HyperdimensionalComputing.grad2bipol-Tuple{Real}"><code>HyperdimensionalComputing.grad2bipol</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">grad2bipol(x::Number)</code></pre><p>Maps a graded number in [0, 1] to the [-1, 1] interval.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/operations.jl#L16-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.graph-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><a class="docstring-binding" href="#HyperdimensionalComputing.graph-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>HyperdimensionalComputing.graph</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">graph(source::T, target::T, directed::Bool = false)</code></pre><p>Graph for <code>source</code>-<code>target</code> pairs. Can be directed or undirected.</p><p><strong>Arguments</strong></p><ul><li><code>source::T</code>: Source node hypervectors</li><li><code>target::T</code>: Target node hypervectors</li><li><code>directed::Bool = false</code>: Whether the graph is directed or not</li></ul><p><strong>Example</strong></p><p><strong>Extended help</strong></p><p>This encoding is based on the following mathematical notation:</p><p><em>Undirected graphs</em></p><p class="math-container">\[\otimes_{i=1}^{m} S_i \otimes T_i\]</p><p><em>Directed graphs</em></p><p class="math-container">\[\otimes_{i=1}^{m} S_i \otimes \Pi(T_i)\]</p><p>where <code>K</code> and <code>V</code> are the key and value hypervector collections, <code>m</code> is the size of the hypervector collection, <code>i</code> is the position of the entry in the collection, and <code>\otimes</code>, <code>\oplus</code> and <code>\Pi</code> are the binding, bundling and shift operations.</p><p><strong>See also</strong></p><ul><li><a href="#HyperdimensionalComputing.hashtable-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>hashtable</code></a>: Hash table encoding, underlying encoding strategy of this encoder.</li></ul><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.graph.html">Torchhd documentation</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L449-L487">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.hashtable-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><a class="docstring-binding" href="#HyperdimensionalComputing.hashtable-Union{Tuple{T}, Tuple{T, T}} where T&lt;:(AbstractVector{&lt;:AbstractHV})"><code>HyperdimensionalComputing.hashtable</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">hashtable(keys::T, values::T) where {T &lt;: AbstractVector{&lt;:AbstractHV}}</code></pre><p>Hash table from keys-values hypervector pairs. Keys and values must be the same length in order to encode as hypervector.</p><p><strong>Arguments</strong></p><ul><li><code>keys::AbstractVector{&lt;:AbstractHV}</code>: Keys hypervectors</li><li><code>values::AbstractVector{&lt;:AbstractHV}</code>: Values hypervectors</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; ks = [BinaryHV(10) for _ in 1:5]
5-element Vector{BinaryHV}:
 [0, 0, 0, 1, 0, 1, 1, 0, 0, 0]
 [1, 0, 1, 0, 1, 0, 1, 0, 1, 1]
 [0, 0, 0, 0, 1, 1, 1, 0, 1, 1]
 [1, 0, 0, 0, 0, 1, 1, 0, 1, 0]
 [0, 1, 1, 1, 1, 0, 0, 1, 1, 1]

julia&gt; vs = [BinaryHV(10) for _ in 1:5]
5-element Vector{BinaryHV}:
 [0, 1, 0, 0, 1, 1, 0, 1, 0, 0]
 [1, 0, 1, 1, 1, 0, 1, 0, 0, 0]
 [0, 0, 0, 0, 0, 1, 1, 0, 1, 0]
 [0, 1, 1, 0, 0, 0, 0, 1, 0, 1]
 [0, 1, 1, 0, 0, 0, 1, 1, 0, 1]

julia&gt; hashtable(ks, vs)
10-element BinaryHV:
 0
 0
 0
 1
 1
 0
 1
 0
 1
 1</code></pre><p><strong>Extended help</strong></p><p>This encoding is based on the following mathematical notation:</p><p class="math-container">\[\oplus_{i=1}^{m} K_i \otimes V_i\]</p><p>where <code>K</code> and <code>V</code> are the key and value hypervector collections, <code>m</code> is the size of the hypervector collection, <code>i</code> is the position of the entry in the collection, and <code>\otimes</code> and <code>\oplus</code> are the binding and bundling operations.</p><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.hash_table.html">Torchhd documentation</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L246-L303">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.level-Union{Tuple{HV}, Tuple{HV, Int64}} where HV&lt;:AbstractHV"><a class="docstring-binding" href="#HyperdimensionalComputing.level-Union{Tuple{HV}, Tuple{HV, Int64}} where HV&lt;:AbstractHV"><code>HyperdimensionalComputing.level</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">level(v::HV, n::Int) where {HV &lt;: AbstractHV}
level(HV::Type{&lt;:AbstractHV}, n::Int; D::Int = 10_000)</code></pre><p>Creates a set of level correlated hypervectors, where the first and last hypervectors are quasi-orthogonal.</p><p><strong>Arguments</strong></p><ul><li><code>v::HV</code>: Base hypervector</li><li><code>n::Int</code>: Number of levels (alternatively, provide a vector to be encoded)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L494-L503">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.multibind-Tuple{AbstractVector{&lt;:AbstractHV}}"><a class="docstring-binding" href="#HyperdimensionalComputing.multibind-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.multibind</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">multibind(vs::AbstractVector{&lt;:AbstractHV})</code></pre><p>Binding of multiple hypervectors, binds all the input hypervectors together.</p><p><strong>Arguments</strong></p><ul><li><code>vs::AbstractVector{&lt;:AbstractHV}</code>: Hypervectors</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; vs = [BinaryHV(10) for _ in 1:10]
10-element Vector{BinaryHV}:
 [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]
 [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]
 [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]
 [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]
 [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]
 [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]
 [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]
 [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]
 [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]
 [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]

julia&gt; multibind(vs)
10-element BinaryHV:
 1
 1
 1
 0
 1
 1
 1
 0
 1
 0</code></pre><p><strong>Extended help</strong></p><p>This encoding is based on the following mathematical notation:</p><p class="math-container">\[\otimes_{i=1}^{m} V_i\]</p><p>where <code>V</code> is the hypervector collection, <code>m</code> is the size of the hypervector collection, <code>i</code> is the position of the entry in the collection, and <code>\otimes</code> is the binding operation.</p><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.multibind.html">Torchhd documentation</a></li></ul><p><strong>See also</strong></p><ul><li><a href="#HyperdimensionalComputing.multiset-Union{Tuple{AbstractVector{&lt;:T}}, Tuple{T}} where T&lt;:AbstractHV"><code>multiset</code></a>: Multiset encoding, bundling-variant of this encoder</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L61-L116">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.multiset-Union{Tuple{AbstractVector{&lt;:T}}, Tuple{T}} where T&lt;:AbstractHV"><a class="docstring-binding" href="#HyperdimensionalComputing.multiset-Union{Tuple{AbstractVector{&lt;:T}}, Tuple{T}} where T&lt;:AbstractHV"><code>HyperdimensionalComputing.multiset</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">multiset(vs::AbstractVector{&lt;:T})::T where {T &lt;: AbstractHV}</code></pre><p>Multiset of input hypervectors, bundles all the input hypervectors together.</p><p><strong>Arguments</strong></p><ul><li><code>vs::AbstractVector{&lt;:AbstractHV}</code>: Hypervectors</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; vs = [BinaryHV(10) for _ in 1:10]
10-element Vector{BinaryHV}:
 [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]
 [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]
 [0, 1, 0, 1, 0, 0, 1, 0, 0, 0]
 [0, 1, 0, 1, 1, 0, 1, 0, 1, 0]
 [1, 1, 0, 0, 1, 0, 1, 1, 1, 0]
 [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]
 [0, 0, 0, 0, 1, 1, 0, 1, 1, 0]
 [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]
 [1, 1, 0, 1, 1, 0, 0, 0, 0, 0]
 [1, 1, 0, 0, 0, 1, 1, 0, 0, 0]

julia&gt; multiset(vs)
10-element BinaryHV:
 0
 1
 0
 0
 1
 0
 0
 0
 1
 0</code></pre><p><strong>Extended help</strong></p><p>This encoding is based on the following mathematical notation:</p><p class="math-container">\[\oplus_{i=1}^{m} V_i\]</p><p>where <code>V</code> is the hypervector collection, <code>m</code> is the size of the hypervector collection, <code>i</code> is the position of the entry in the collection, and <code>\oplus</code> is the bundling operation.</p><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.multiset.html">Torchhd documentation</a></li></ul><p><strong>See also</strong></p><ul><li><a href="#HyperdimensionalComputing.multibind-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>multibind</code></a>: Multibind encoding, binding-variant of this encoder</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L1-L56">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.nearest_neighbor-Tuple{AbstractHV, Any, Int64}"><a class="docstring-binding" href="#HyperdimensionalComputing.nearest_neighbor-Tuple{AbstractHV, Any, Int64}"><code>HyperdimensionalComputing.nearest_neighbor</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">nearest_neighbor(u::AbstractHV, collection[, k::Int]; kwargs...)</code></pre><p>Returns the element of <code>collection</code> that is most similar to <code>u</code>. </p><p>Function outputs <code>(τ, i, xi)</code> with <code>τ</code> the highest similarity value, <code>i</code> the index (or key if <code>collection</code> is a dictionary) of the closest  neighbor and <code>xi</code> the closest vector. <code>kwargs</code> is an optional argument for the similarity search.</p><p>If a number <code>k</code> is given, the <code>k</code> closest neighbor are returned, as a sorted list of <code>(τ, i)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/inference.jl#L90-L102">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.ngrams"><a class="docstring-binding" href="#HyperdimensionalComputing.ngrams"><code>HyperdimensionalComputing.ngrams</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ngrams(vs::AbstractVector{&lt;:AbstractHV}, n::Int = 3)</code></pre><p>Creates a hypervector with the <em>n</em>-gram statistics of the input.</p><p><strong>Arguments</strong></p><ul><li><code>vs::AbstractVector{&lt;:AbstractHV}</code>: Hypervector collection</li><li><code>n::Int = 3</code>: <em>n</em>-gram size</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; vs = [BinaryHV(10) for _ in 1:10]
10-element Vector{BinaryHV}:
 [0, 1, 0, 0, 1, 0, 1, 0, 0, 1]
 [0, 0, 1, 1, 1, 0, 0, 1, 1, 1]
 [0, 0, 1, 0, 0, 1, 1, 1, 0, 0]
 [1, 0, 0, 0, 1, 0, 0, 1, 1, 1]
 [0, 1, 0, 0, 1, 0, 1, 1, 0, 0]
 [1, 1, 1, 0, 1, 0, 0, 1, 0, 1]
 [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]
 [0, 1, 0, 1, 0, 0, 0, 1, 1, 0]
 [0, 0, 0, 1, 1, 1, 1, 0, 0, 1]
 [1, 1, 0, 0, 0, 1, 1, 1, 0, 1]

julia&gt; ngrams(vs)
10-element BinaryHV:
 1
 1
 1
 1
 1
 1
 0
 1
 0
 1</code></pre><p><strong>Extended help</strong></p><p>This encoding is defined by the following mathematical notation:</p><p class="math-container">\[\oplus_{i=1}^{m-n}\otimes_{j=1}^{n-1}\Pi^{n-j-1}(V_{i+j})\]</p><p>where <code>V</code> is the collection of hypervectors, <code>m</code> is the number of hypervectors in the collection <code>V</code>, <code>n</code> is the window size, <code>i</code> is the position in the sequence, <code>j</code> is the position in the <em>n</em>-gram, and <code>\oplus</code>, <code>\otimes</code> and <code>\Pi</code> are the bundling, binding and shift operations.</p><div class="admonition is-info" id="Note-570688460063bb82"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-570688460063bb82" title="Permalink"></a></header><div class="admonition-body"><ul><li>For <code>n = 1</code> use <code>multiset()</code> instead</li><li>For <code>n = m</code> use <code>bindsequence()</code> instead</li></ul></div></div><p><strong>See also</strong></p><ul><li><a href="#HyperdimensionalComputing.multiset-Union{Tuple{AbstractVector{&lt;:T}}, Tuple{T}} where T&lt;:AbstractHV"><code>multiset</code></a>: Multiset encoding, equivalent to <code>ngram(vs, 1)</code></li><li><a href="#HyperdimensionalComputing.bindsequence-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>bindsequence</code></a>: Bind-sequence encoding, equivalent to <code>ngram(vs, length(vs))</code></li></ul><p><strong>References</strong></p><ul><li><a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.ngrams.html">Torchhd documentation</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/encoding.jl#L377-L441">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.similarity-Tuple{AbstractHV}"><a class="docstring-binding" href="#HyperdimensionalComputing.similarity-Tuple{AbstractHV}"><code>HyperdimensionalComputing.similarity</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">similarity(u::AbstractHV; [method])</code></pre><p>Create a function that computes the similarity between its argument and <code>u</code><code>using</code>similarity<code>, i.e. a function equivalent to</code>v -&gt; similarity(u, v)`.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/inference.jl#L62-L67">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.similarity-Tuple{AbstractVector, AbstractVector}"><a class="docstring-binding" href="#HyperdimensionalComputing.similarity-Tuple{AbstractVector, AbstractVector}"><code>HyperdimensionalComputing.similarity</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">similarity(u::AbstractVector, v::AbstractVector; method::Symbol)</code></pre><p>Computes similarity between two (hyper)vectors using a <code>method</code> ∈ <code>[:cosine, :jaccard, :hamming]</code>. When no method is given, a default is used (cosine for vectors that can have negative elements and Jaccard for those that only have positive elements).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/inference.jl#L24-L31">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.similarity-Tuple{AbstractVector{&lt;:AbstractHV}}"><a class="docstring-binding" href="#HyperdimensionalComputing.similarity-Tuple{AbstractVector{&lt;:AbstractHV}}"><code>HyperdimensionalComputing.similarity</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">similarity(hvs::AbstractVector{&lt;:AbstractHV}; [method])</code></pre><p>Computes the similarity matrix for a vector of hypervectors using the similarity metrics defined by the pairwise version of <code>similarity</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/inference.jl#L45-L50">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.δ"><a class="docstring-binding" href="#HyperdimensionalComputing.δ"><code>HyperdimensionalComputing.δ</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">δ(u::AbstractHV, v::AbstractHV; [method])
δ(u::AbstractHV; [method])
δ(hvs::AbstractVector{&lt;:AbstractHV}; [method])</code></pre><p>Alias for <code>similarity</code>. See <code>similarity</code> for the main documentation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/inference.jl#L71-L77">source</a></section></details></article><h2 id="Types"><a class="docs-heading-anchor" href="#Types">Types</a><a id="Types-1"></a><a class="docs-heading-anchor-permalink" href="#Types" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.BinaryHV"><a class="docstring-binding" href="#HyperdimensionalComputing.BinaryHV"><code>HyperdimensionalComputing.BinaryHV</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">BinaryHV</code></pre><p>A ternary hypervector type based on the Binary Splatter Code (BSC) vector symbolic architecture (Kanerva, 1994; Kanerva, 1995; Kanerva, 1996; Kanerva, 1997).</p><p>Represents a hypervector boolean elements, i.e. <code>(false, true)</code>.</p><p><strong>Extended help</strong></p><p><strong>References</strong></p><ul><li>Kanerva, P. (1994). The Spatter Code for Encoding Concepts at Many Levels. In International Conference on Artificial Neural Networks (ICANN), pages 226–229.</li><li>Kanerva, P. (1995). A Family of Binary Spatter Codes. In International Conference on Artificial Neural Networks (ICANN), pages 517–522.</li><li>Kanerva, P. (1996). Binary Spatter-Coding of Ordered K-tuples. In International Conference on Artificial Neural Networks (ICANN), volume 1112 of Lecture Notes in Computer Science, pages 869–873.</li><li>Kanerva, P. (1997). Fully Distributed Representation. In Real World Computing Symposium (RWC), pages 358–365.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/types.jl#L120-L136">source</a></section></details></article><article><details class="docstring" open="true"><summary id="HyperdimensionalComputing.TernaryHV"><a class="docstring-binding" href="#HyperdimensionalComputing.TernaryHV"><code>HyperdimensionalComputing.TernaryHV</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TernaryHV</code></pre><p>A ternary hypervector type based on the Multiply-Add-Permute (MAP) vector symbolic architecture (Gayler, 1998).</p><p>Represents a hypervector with elements in <code>(-1, 1)</code>.</p><p><strong>Extended help</strong></p><p><strong>References</strong></p><ul><li>Gayler, R. W. (1998). Multiplicative Binding, Representation Operators &amp; Analogy. In Advances in Analogy Research: Integration of Theory and Data from the Cognitive, Computational, and Neural Sciences, pages 1–4.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/cvigilv/HyperdimensionalComputing.jl/blob/b768ac610cbfe808bdb96d5b9ac6249b9114b537/src/types.jl#L77-L90">source</a></section></details></article><h2 id="Constants"><a class="docs-heading-anchor" href="#Constants">Constants</a><a id="Constants-1"></a><a class="docs-heading-anchor-permalink" href="#Constants" title="Permalink"></a></h2><h2 id="Macros"><a class="docs-heading-anchor" href="#Macros">Macros</a><a id="Macros-1"></a><a class="docs-heading-anchor-permalink" href="#Macros" title="Permalink"></a></h2></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/whats-the-dollar-of-mexico/">« What&#39;s the Dollar of Mexico?</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 15 December 2025 15:29">Monday 15 December 2025</span>. Using Julia version 1.12.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
