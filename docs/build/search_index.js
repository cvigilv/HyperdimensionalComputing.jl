var documenterSearchIndex = {"docs":
[{"location":"api.html#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"This page contains the complete API reference for HyperdimensionalComputing.jl.","category":"page"},{"location":"api.html#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"api.html#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"api.html#HyperdimensionalComputing.bipol2grad-Tuple{Number}","page":"API","title":"HyperdimensionalComputing.bipol2grad","text":"bipol2grad(x::Number)\n\nMaps a bipolar number in [-1, 1] to the [0, 1] interval.\n\n\n\n\n\n","category":"method"},{"location":"api.html#HyperdimensionalComputing.grad2bipol-Tuple{Number}","page":"API","title":"HyperdimensionalComputing.grad2bipol","text":"grad2bipol(x::Number)\n\nMaps a graded number in [0, 1] to the [-1, 1] interval.\n\n\n\n\n\n","category":"method"},{"location":"api.html#Types","page":"API","title":"Types","text":"","category":"section"},{"location":"api.html#Constants","page":"API","title":"Constants","text":"","category":"section"},{"location":"api.html#Macros","page":"API","title":"Macros","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html#Introduction-to-Hyperdimensional-Computing-with-HyperdimensionalComputing.jl","page":"Introduction to HDC","title":"Introduction to Hyperdimensional Computing with HyperdimensionalComputing.jl","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html#Introduction","page":"Introduction to HDC","title":"Introduction","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Hyperdimensional Computing (HDC) is a brain-inspired computational paradigm that represents and manipulates information using high-dimensional vectors called hypervectors. These vectors typically have thousands of dimensions (often 1,000-10,000), making them \"hyperdimensional.\"","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"The key insight is that high-dimensional spaces have unique mathematical properties that allow for robust, fault-tolerant computation. Think of it like having a vast library where each book (hypervector) has so many pages that even if you change a few pages, you can still identify which book it is.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Rather than the specific choice of the values in the hyperdimensional representations, we identify 4 hallmarks that distinguish hyperdimensional computing from other approaches:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Hyperdimensional: The HVs live in a very high-dimensional space, large enough such that","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"random components can be seen as distinct and dissimilar from one another;","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Homogeneous: The vast majority of HVs all have highly similar properties: they have","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"(approximately) the same norm, are all equally (dis)similar to one another, and have the same dimensionality, even if they embed more complex information;","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Holographic: The information encoded in an HV is distributed over its many dimensions;","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"no specific region is more informative than another for a specific piece of information;","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Robust: Randomly changing a modest number of the components does not substantially change","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"an HV's meaning.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"The basic operations needed for HDC are remarkably simple. They hinge on 4 operations to manipulate and extract the information in the HVs:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Generating new HVs from scratch;\nCombining a set of HVs into a new HV that is similar to all;\nUsing one or more HVs to generate a new one that is dissimilar to its parent(s);\nComparing 2 HVs to detect whether they are more (dis)similar than expected by chance.","category":"page"},{"location":"examples/introduction-to-hdc.html#1.-Hypervector-Creation","page":"Introduction to HDC","title":"1. Hypervector Creation","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html#Bipolar-Hypervectors","page":"Introduction to HDC","title":"Bipolar Hypervectors","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"In this tutorial, we'll focus on bipolar hypervectors - vectors containing only -1s and +1s. A typical bipolar hypervector has dimension D (e.g., D = 10000) where each element is randomly assigned:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"mathbfh in -1+1^D","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For example, a 8-dimensional bipolar hypervector might look like: mathbfh = +1 -1 +1 +1 -1 -1 +1 -1","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"To generate a bipolar hypervector with HyperdimensionalComputing.jl package, you can do the following:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"using HyperdimensionalComputing\n\nh = BipolarHDV()","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"This will create a random vector of -1s and +1s of 10.000 dimensions.","category":"page"},{"location":"examples/introduction-to-hdc.html#Key-Properties","page":"Introduction to HDC","title":"Key Properties","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Quasi-orthogonality: Randomly generated bipolar hypervectors are approximately orthogonal to each other. In high dimensions, the probability that two random bipolar vectors are similar becomes vanishingly small - like finding two identical snowflakes.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Distance Preservation: The cosine similarity between random bipolar hypervectors follows a normal distribution centered around 0.","category":"page"},{"location":"examples/introduction-to-hdc.html#2.-Fundamental-Operations","page":"Introduction to HDC","title":"2. Fundamental Operations","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"HDC uses three primary operations that preserve the hyperdimensional properties:","category":"page"},{"location":"examples/introduction-to-hdc.html#2.1-Bundling-(Superposition)","page":"Introduction to HDC","title":"2.1 Bundling (Superposition)","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Bundling combines multiple hypervectors to create a summary vector that contains information from all inputs. Think of it as creating a \"blend\" that retains traces of all ingredients.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For bipolar vectors, bundling uses majority voting:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"textBundle(mathbfh_1 mathbfh_2  mathbfh_n)_i = begincases\n+1  textif  sum_j=1^n h_ji  0 \n-1  textotherwise\nendcases","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Example: Bundling three 8-dimensional vectors:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"mathbfa = +1 -1 +1 +1 -1 -1 +1 -1\nmathbfb = -1 +1 +1 -1 +1 -1 +1 +1\nmathbfc = +1 +1 -1 +1 -1 +1 +1 -1","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Result: textBundle(mathbfa mathbfb mathbfc) = +1 +1 +1 +1 -1 -1 +1 -1","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"In HyperdimensionalComputing.jl, this is done as follows:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ = BipolarHDV([ 1, -1,  1,  1, -1, -1,  1, -1])\nh₂ = BipolarHDV([-1,  1,  1, -1,  1, -1,  1,  1])\nh₃ = BipolarHDV([ 1,  1, -1,  1, -1,  1,  1, -1])\naggregate([h₁, h₂, h₃])","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"You can also do the same using the + operator:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ + h₂ + h₃","category":"page"},{"location":"examples/introduction-to-hdc.html#2.2-Binding","page":"Introduction to HDC","title":"2.2 Binding","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Binding creates associations between hypervectors, similar to forming key-value pairs. The bound result is dissimilar to both inputs, but can be \"unbound\" using one input to retrieve the other.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For bipolar vectors, binding uses element-wise multiplication:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"textBind(mathbfa mathbfb) = mathbfa odot mathbfb","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Example:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"mathbfa = +1 -1 +1 +1 -1 -1 +1 -1\nmathbfb = -1 +1 +1 -1 +1 -1 +1 +1\nmathbfa odot mathbfb = -1 -1 +1 -1 -1 +1 +1 -1","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"In HyperdimensionalComputing.jl, binding can be done using the bind function: * operators:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"bound = bind([h₁, h₂])","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"or the * operator:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₁ * h₂","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Unbinding: Since element-wise multiplication is its own inverse for bipolar vectors, (mathbfa odot mathbfb) odot mathbfa = mathbfb, we can unbind information from a hypervector as follows:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"retrieved = bound * h₁","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"h₂ == retrieved","category":"page"},{"location":"examples/introduction-to-hdc.html#2.3-Shifting/Permutation","page":"Introduction to HDC","title":"2.3 Shifting/Permutation","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Shifting (or permutation) creates new hypervectors that are orthogonal to the original while preserving structure. It's like rearranging the elements according to a fixed pattern.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For bipolar vectors, a common approach is circular shifting:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"textShift(mathbfh k)_i = h_(i-k) bmod D","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Example with right shift by 2:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Original: +1 -1 +1 +1 -1 -1 +1 -1\nShifted: +1 -1 +1 -1 +1 +1 -1 -1","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"In HyperdimensionalComputing.jl, this is done with the Π (\\Pi) operator:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Π(h₁, 2)","category":"page"},{"location":"examples/introduction-to-hdc.html#2.4-Similarity-Measurement","page":"Introduction to HDC","title":"2.4 Similarity Measurement","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For classification and retrieval, we measure similarity using cosine similarity for bipolar vectors:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"textSimilarity(mathbfa mathbfb) = fracmathbfa cdot mathbfbmathbfamathbfb = fracmathbfa cdot mathbfbD","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Since bipolar vectors have unit magnitude (mathbfh = sqrtD), the cosine similarity simplifies to the normalized dot product:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"textSimilarity(mathbfa mathbfb) = fracmathbfa cdot mathbfbD","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"sim = similarity(h₁, h₂)","category":"page"},{"location":"examples/introduction-to-hdc.html#3.-Encoding-Data-as-Hypervectors","page":"Introduction to HDC","title":"3. Encoding Data as Hypervectors","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"The true power of HDC emerges when we combine the fundamental operations to encode complex data structures as hypervectors. By creatively applying bundling, binding, and shifting, we can represent virtually any type of information - from sequences and hierarchies to graphs and associative memories. The operations act as building blocks that can be composed in countless ways, limited only by our imagination and the specific requirements of our application. Let's explore two fundamental encoding strategies that demonstrate this flexibility.","category":"page"},{"location":"examples/introduction-to-hdc.html#3.1-N-gram-Encoding","page":"Introduction to HDC","title":"3.1 N-gram Encoding","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"N-grams represent sequences by encoding the order of elements. This is particularly useful for text processing where word order matters.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Approach:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Assign a unique hypervector to each symbol\nUse shifting to represent position\nBundle all positions to create the n-gram","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Mathematical formulation for trigram \"ABC\":","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"mathbftrigram = mathbfA odot textShift(mathbfB 1) odot textShift(mathbfC 2)","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Example: For the word \"CAT\":","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Bigrams: \"CA\", \"AT\"\nmathbfCA = mathbfC odot textShift(mathbfA 1)\nmathbfAT = mathbfA odot textShift(mathbfT 1)\nWord representation: textBundle(mathbfCA mathbfAT)","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"function encodengrams(text::String, n::Int, dimension::Int=1000)     # Create symbol dictionary     symbols = Dict{Char, Vector{Int}}()     for char in unique(text)         symbols[char] = randombipolar_vector(dimension)     end","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"# Generate n-grams\nngram_vectors = Vector{Vector{Int}}()\n\nfor i in 1:(length(text) - n + 1)\n    ngram = text[i:i+n-1]\n    ngram_vector = symbols[ngram[1]]\n\n    for j in 2:length(ngram)\n        shifted = ∏(symbols[ngram[j]], j-1)\n        ngram_vector = bind(ngram_vector, shifted)\n    end\n\n    push!(ngram_vectors, ngram_vector)\nend\n\nreturn bundle(ngram_vectors)","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"end","category":"page"},{"location":"examples/introduction-to-hdc.html#Create-n-gram-encoding-for-a-sequence","page":"Introduction to HDC","title":"Create n-gram encoding for a sequence","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"wordvector = encodengrams(\"CAT\", 2) println(\"Encoded 'CAT' with bigrams, vector length: \", length(word_vector))","category":"page"},{"location":"examples/introduction-to-hdc.html#3.2-Hash-Table-Encoding","page":"Introduction to HDC","title":"3.2 Hash Table Encoding","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Hash tables in HDC map keys to values using binding, creating associative memories that can handle noise and incomplete queries.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Construction:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For each key-value pair (k_i v_i), create mathbfk_i odot mathbfv_i\nBundle all bound pairs: mathbfM = textBundle(mathbfk_1 odot mathbfv_1 mathbfk_2 odot mathbfv_2 )","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Retrieval: To query key mathbfq, compute mathbfM odot mathbfq and find the closest stored value.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Example: Storing animal-sound associations:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Store: (\"dog\", \"bark\"), (\"cat\", \"meow\"), (\"cow\", \"moo\")\nMemory: mathbfM = textBundle(mathbfdog odot mathbfbark mathbfcat odot mathbfmeow mathbfcow odot mathbfmoo)\nQuery \"dog\": mathbfM odot mathbfdog approx mathbfbark","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"function createhashtable(keyvaluepairs::Vector{Tuple{String, String}}, dimension::Int=1000)     # Create symbol dictionaries     keys = Dict{String, Vector{Int}}()     values = Dict{String, Vector{Int}}()","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"for (k, v) in key_value_pairs\n    if !haskey(keys, k)\n        keys[k] = random_bipolar_vector(dimension)\n    end\n    if !haskey(values, v)\n        values[v] = random_bipolar_vector(dimension)\n    end\nend\n\n# Create bound pairs and bundle them\nbound_pairs = [bind(keys[k], values[v]) for (k, v) in key_value_pairs]\nmemory = bundle(bound_pairs)\n\nreturn (memory, keys, values)","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"end","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"function queryhashtable(memory::Vector{Int}, querykey::Vector{Int}, values::Dict{String, Vector{Int}})     # Unbind with query key     result = bind(memory, querykey)","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"# Find most similar value\nbest_match = \"\"\nbest_similarity = -Inf\n\nfor (value_name, value_vector) in values\n    sim = cosine_similarity(result, value_vector)\n    if sim > best_similarity\n        best_similarity = sim\n        best_match = value_name\n    end\nend\n\nreturn best_match, best_similarity","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"end","category":"page"},{"location":"examples/introduction-to-hdc.html#Create-and-query-HDC-hash-table","page":"Introduction to HDC","title":"Create and query HDC hash table","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"keyvaluepairs = [(\"dog\", \"bark\"), (\"cat\", \"meow\"), (\"cow\", \"moo\")] memory, keys, values = createhashtable(keyvaluepairs)","category":"page"},{"location":"examples/introduction-to-hdc.html#Query-the-hash-table","page":"Introduction to HDC","title":"Query the hash table","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"result, similarity = queryhashtable(memory, keys[\"dog\"], values) println(\"Query 'dog' result: \", result, \" (similarity: \", similarity, \")\")","category":"page"},{"location":"examples/introduction-to-hdc.html#4.-Basic-Learning-via-Prototype-Generation","page":"Introduction to HDC","title":"4. Basic Learning via Prototype Generation","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html#4.1-Sum-All-Hypervectors-Approach","page":"Introduction to HDC","title":"4.1 Sum-All-Hypervectors Approach","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"The simplest learning method creates class prototypes by bundling all training examples belonging to each class.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Algorithm:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"For each class c, bundle all training examples: mathbfP_c = textBundle(mathbfx_1 mathbfx_2  mathbfx_n) where mathbfx_i in c\nFor classification, compute similarity between test example and each prototype\nAssign to the most similar class","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Language Detection Example:","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"English prototype: Bundle all English text hypervectors\nSpanish prototype: Bundle all Spanish text hypervectors\nFrench prototype: Bundle all French text hypervectors","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"function trainprototypes(trainingdata::Dict{String, Vector{Vector{Int}}})     prototypes = Dict{String, Vector{Int}}()","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"for (language, examples) in training_data\n    prototypes[language] = bundle(examples)\nend\n\nreturn prototypes","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"end","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"function classifytext(testvector::Vector{Int}, prototypes::Dict{String, Vector{Int}})     bestlanguage = \"\"     bestsimilarity = -Inf","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"for (language, prototype) in prototypes\n    sim = cosine_similarity(test_vector, prototype)\n    if sim > best_similarity\n        best_similarity = sim\n        best_language = language\n    end\nend\n\nreturn best_language, best_similarity","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"end","category":"page"},{"location":"examples/introduction-to-hdc.html#Example-with-simulated-language-data","page":"Introduction to HDC","title":"Example with simulated language data","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"englishexamples = [randombipolarvector(1000) for _ in 1:10] spanishexamples = [randombipolarvector(1000) for _ in 1:10] frenchexamples = [randombipolar_vector(1000) for _ in 1:10]","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"trainingdata = Dict(     \"English\" => englishexamples,     \"Spanish\" => spanishexamples,     \"French\" => frenchexamples )","category":"page"},{"location":"examples/introduction-to-hdc.html#Train-prototypes-for-each-language","page":"Introduction to HDC","title":"Train prototypes for each language","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"prototypes = trainprototypes(trainingdata)","category":"page"},{"location":"examples/introduction-to-hdc.html#Classify-new-text","page":"Introduction to HDC","title":"Classify new text","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"testtext = randombipolarvector(1000) predictedlanguage, similarity = classifytext(testtext, prototypes) println(\"Predicted language: \", predicted_language, \" (similarity: \", similarity, \")\")","category":"page"},{"location":"examples/introduction-to-hdc.html#Summary","page":"Introduction to HDC","title":"Summary","text":"","category":"section"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"Hyperdimensional Computing provides a robust framework for representing and processing information using high-dimensional bipolar vectors. The three fundamental operations (bundling, binding, and shifting) enable complex computations while maintaining interpretability and fault tolerance. Through encodings like n-grams and hash tables, HDC can handle structured data, while learning algorithms enable adaptive classification systems that improve with experience.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"The power of HDC lies in its simplicity: using only basic operations on bipolar vectors, it can solve complex problems in machine learning, natural language processing, and cognitive computing while remaining transparent and interpretable.","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"","category":"page"},{"location":"examples/introduction-to-hdc.html","page":"Introduction to HDC","title":"Introduction to HDC","text":"This page was generated using Literate.jl.","category":"page"},{"location":"index.html#HyperdimensionalComputing.jl","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"","category":"section"},{"location":"index.html","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"Documentation for HyperdimensionalComputing.","category":"page"},{"location":"index.html#Overview","page":"HyperdimensionalComputing.jl","title":"Overview","text":"","category":"section"},{"location":"index.html","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"HyperdimensionalComputing.jl provides...","category":"page"},{"location":"index.html#Manual","page":"HyperdimensionalComputing.jl","title":"Manual","text":"","category":"section"},{"location":"index.html","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"Pages = [\n    \"api.md\",\n    \"examples.md\"\n]\nDepth = 2","category":"page"},{"location":"index.html#Index","page":"HyperdimensionalComputing.jl","title":"Index","text":"","category":"section"},{"location":"index.html","page":"HyperdimensionalComputing.jl","title":"HyperdimensionalComputing.jl","text":"Pages = [\"index.md\"]","category":"page"}]
}
